{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3535973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load, split, ScaleAbsOne\n",
    "from gpytorch.constraints import Positive\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5e03b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.55it/s]\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "df = load()\n",
    "train, dev, test = split(df, \"new_dose-response_matrices\", inner_fold=1, outer_fold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2cd648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train.pop(\"PercentageGrowth\")\n",
    "dev_target = dev.pop(\"PercentageGrowth\")\n",
    "test_target = test.pop(\"PercentageGrowth\")\n",
    "scaler = ScaleAbsOne()\n",
    "train = scaler.fit_transform(train.values)\n",
    "dev = scaler.transform(dev.values)\n",
    "test = scaler.transform(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f337336",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = torch.tensor(train[:150]).float()\n",
    "subt = torch.tensor(train_target[:150].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd15c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69dcc0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 50\n",
    "\n",
    "# Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 100)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)\n",
    "\n",
    "# Wrap training, prediction and plotting from the ExactGP-Tutorial into a function,\n",
    "# so that we do not have to repeat the code later on\n",
    "def train(model, likelihood, training_iter=training_iter):\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(sub)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, subt)\n",
    "        print(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "# def predict(model, likelihood, test_x = torch.linspace(0, 1, 51)):\n",
    "#     model.eval()\n",
    "#     likelihood.eval()\n",
    "#     # Make predictions by feeding model through likelihood\n",
    "#     with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "#         # Test points are regularly spaced along [0,1]\n",
    "#         return likelihood(model(test_x))\n",
    "\n",
    "def plot(observed_pred, test_x=torch.linspace(0, 1, 51)):\n",
    "    with torch.no_grad():\n",
    "        # Initialize plot\n",
    "        f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "        # Get upper and lower confidence bounds\n",
    "        lower, upper = observed_pred.confidence_region()\n",
    "        # Plot training data as black stars\n",
    "        ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "        # Plot predictive means as blue line\n",
    "        ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "        # Shade between the lower and upper confidence bounds\n",
    "        ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "        ax.set_ylim([-3, 3])\n",
    "        ax.legend(['Observed Data', 'Mean', 'Confidence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ed4af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import positivity constraint\n",
    "from gpytorch.constraints import Positive\n",
    "\n",
    "class MultiLinearKernel(gpytorch.kernels.Kernel):\n",
    "    # the sinc kernel is stationary\n",
    "    is_stationary = False\n",
    "\n",
    "    # We will register the parameter when initializing the kernel\n",
    "    def __init__(self, length_prior=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # register the raw parameter\n",
    "        self.register_parameter(\n",
    "            name='raw_length', parameter=torch.nn.Parameter(torch.ones(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # set the parameter constraint to be positive, when nothing is specified\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "\n",
    "        # register the constraint\n",
    "        self.register_constraint(\"raw_length\", length_constraint)\n",
    "\n",
    "        # set the parameter prior, see\n",
    "        # https://docs.gpytorch.ai/en/latest/module.html#gpytorch.Module.register_prior\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"length_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.length,\n",
    "                lambda m, v : m._set_length(v),\n",
    "            )\n",
    "\n",
    "    # now set up the 'actual' paramter\n",
    "    @property\n",
    "    def length(self):\n",
    "        # when accessing the parameter, apply the constraint transform\n",
    "        return self.raw_length_constraint.transform(self.raw_length)\n",
    "\n",
    "    @length.setter\n",
    "    def length(self, value):\n",
    "        return self._set_length(value)\n",
    "\n",
    "    def _set_length(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_length)\n",
    "        # when setting the paramater, transform the actual value to a raw one by applying the inverse transform\n",
    "        self.initialize(raw_length=self.raw_length_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        prod = torch.einsum(\"nd, md -> nmd\", x1, x2)\n",
    "        frac = (self.length**2 + prod) / (1 + self.length**2)\n",
    "        return frac.prod(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "827ee70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4466.27685546875\n",
      "4149.9970703125\n",
      "3863.368408203125\n",
      "3603.886962890625\n",
      "3369.152587890625\n",
      "3156.885986328125\n",
      "2964.94970703125\n",
      "2791.355712890625\n",
      "2634.272216796875\n",
      "2492.019775390625\n",
      "2363.072509765625\n",
      "2246.047607421875\n",
      "2139.700927734375\n",
      "2042.9156494140625\n",
      "1954.690185546875\n",
      "1874.1331787109375\n",
      "1800.4478759765625\n",
      "1732.9251708984375\n",
      "1670.9365234375\n",
      "1613.9205322265625\n",
      "1561.37939453125\n",
      "1512.86962890625\n",
      "1467.99755859375\n",
      "1426.41162109375\n",
      "1387.79931640625\n",
      "1351.8817138671875\n",
      "1318.409423828125\n",
      "1287.16015625\n",
      "1257.934326171875\n",
      "1230.5531005859375\n",
      "1204.85595703125\n",
      "1180.6988525390625\n",
      "1157.95166015625\n",
      "1136.4976806640625\n",
      "1116.231201171875\n",
      "1097.0565185546875\n",
      "1078.887451171875\n",
      "1061.6458740234375\n",
      "1045.2603759765625\n",
      "1029.66650390625\n",
      "1014.8057250976562\n",
      "1000.6240844726562\n",
      "987.0734252929688\n",
      "974.1083374023438\n",
      "961.688720703125\n",
      "949.7771606445312\n",
      "938.33935546875\n",
      "927.3441772460938\n",
      "916.7628173828125\n",
      "906.5689697265625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the simplest form of GP model, exact inference\n",
    "class MultiLinearGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = MultiLinearKernel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize the new model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = MultiLinearGPModel(sub, subt, likelihood)\n",
    "\n",
    "\n",
    "# set to training mode and train\n",
    "model.train()\n",
    "likelihood.train()\n",
    "train(model, likelihood)\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode and predict\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "# observed_pred = predict(model, likelihood)\n",
    "# plot results\n",
    "# plot(observed_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
