{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3535973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load, split, ScaleAbsOne\n",
    "from gpytorch.constraints import Positive\n",
    "import torch\n",
    "import math\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e03b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "df = load()\n",
    "train_set, dev_set, test_set = split(df, \"new_dose-response_matrices\", inner_fold=1, outer_fold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2cd648c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f337336",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = torch.tensor(train_set[:150]).float()\n",
    "subt = torch.tensor(train_target[:150].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28dc5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = torch.randn(150, 400)\n",
    "# subt = torch.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69dcc0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, likelihood, training_iter, x, y):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    pbar = tqdm(range(training_iter)) \n",
    "    for i in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = -mll(output, y)\n",
    "        pbar.set_description(f'{loss.item():.2e}')\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ed4af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLinearKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = False\n",
    "    def __init__(self, length_prior=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.register_parameter(\n",
    "            name='raw_length', \n",
    "            parameter=torch.nn.Parameter(torch.ones(*self.batch_shape, 1, 1, 400) * 100)\n",
    "        )\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        self.register_constraint(\"raw_length\", length_constraint)\n",
    "\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"length_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.length,\n",
    "                lambda m, v : m._set_length(v),\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def length(self):\n",
    "        return self.raw_length_constraint.transform(self.raw_length)\n",
    "\n",
    "    @length.setter\n",
    "    def length(self, value):\n",
    "        return self._set_length(value)\n",
    "\n",
    "    def _set_length(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_length)\n",
    "        self.initialize(raw_length=self.raw_length_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        # This is expensive, but I'm not sure how to improve it\n",
    "        # For the Gram at least it's a symmetric tensor\n",
    "        # We could do it iteratively and at least save some RAM\n",
    "        prod = torch.einsum(\"nd, md -> nmd\", x1, x2)\n",
    "        frac = (self.length**2 + prod) / (1 + self.length**2)\n",
    "        return frac.prod(-1)\n",
    "    \n",
    "class LogMLK(MultiLinearKernel):\n",
    "    def forward(self, x1, x2, **params):\n",
    "        # This is expensive, but I'm not sure how to improve it\n",
    "        # For the Gram at least it's a symmetric tensor\n",
    "        # We could do it iteratively and at least save some RAM\n",
    "        prod = torch.einsum(\"nd, md -> nmd\", x1, x2)\n",
    "        frac = (self.length**2 + prod).log() -torch.log(1 + self.length**2)\n",
    "        return frac.sum(-1)\n",
    "    \n",
    "    \n",
    "class MultiLinearGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, lazy=False):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        if not lazy:\n",
    "            self.covar_module = MultiLinearKernel()\n",
    "        else:\n",
    "            self.covar_module = LazyMultilinearKernel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "    \n",
    "from gpytorch.lazy import lazify\n",
    "from torch.nn import ModuleList\n",
    "class LazyMultilinearKernel(gpytorch.kernels.Kernel):\n",
    "    #Shamelessly copied/adapted from Gpytorch Productkernel and Gabriel\n",
    "    @property\n",
    "    def is_stationary(self) -> bool:\n",
    "        \"\"\"\n",
    "        Kernel is stationary if all components are stationary.\n",
    "        \"\"\"\n",
    "        return False\n",
    "\n",
    "    def __init__(self, length_prior=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.kernels = ModuleList([gpytorch.kernels.PolynomialKernel(power=1) for _ in range(400)])\n",
    "        self._set_offset(1.)\n",
    "        \n",
    "\n",
    "    def forward(self, x1, x2, diag=False, **params):\n",
    "        div_terms = (self.get_offsets() + 1)\n",
    "        def get_term(d):\n",
    "            k = self.kernels[d]\n",
    "            return k(x1[...,d].unsqueeze(1), x2[...,d].unsqueeze(1), diag=diag, **params)/div_terms[d]\n",
    "\n",
    "                \n",
    "        x1_eq_x2 = torch.equal(x1, x2)\n",
    "\n",
    "        if not x1_eq_x2:\n",
    "            # If x1 != x2, then we can't make a MulLazyTensor \n",
    "            # because the kernel won't necessarily be square/symmetric\n",
    "            res = delazify(get_term(0))\n",
    "        else:\n",
    "            res = get_term(0)\n",
    "\n",
    "            if not diag:\n",
    "                res = lazify(res)\n",
    "\n",
    "        for d in range(1, 400):\n",
    "            next_term = get_term(d)\n",
    "            if not x1_eq_x2:\n",
    "                # Again delazify if x1 != x2\n",
    "                res = res * delazify(next_term)\n",
    "            else:\n",
    "                if not diag:\n",
    "                    res = res * lazify(next_term)\n",
    "                else:\n",
    "                    res = res * next_term\n",
    "        return res\n",
    "\n",
    "\n",
    "    def _set_offset(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.kernels[0].raw_offset)\n",
    "        for k in self.kernels:\n",
    "            k._set_offset(value)\n",
    "            \n",
    "    def get_offsets(self):\n",
    "        return torch.cat([k.offset for k in self.kernels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8406c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe3e9524fd348478ed20f667ae095e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = MultiLinearGPModel(sub, subt, likelihood, lazy=True)\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "train(model, likelihood, 100, sub, subt)\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "827ee70c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f44335e1844f2ba91189dde7d0a678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = MultiLinearGPModel(sub, subt, likelihood, lazy=False)\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "train(model, likelihood, 100, sub, subt)\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "530a5aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5b0c194640>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(sub.shape[-1]), model.covar_module.length.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "def00bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = LogMLK()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bcaf583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0756]], grad_fn=<MmBackward>)\n",
      "tensor([[0.6433]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.3332]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6217]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1415]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.5643]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.6458]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.4092]], grad_fn=<MmBackward>)\n",
      "tensor([[10.5152]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.8986]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.4236]], grad_fn=<MmBackward>)\n",
      "tensor([[6.2425]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.7134]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.7303]], grad_fn=<MmBackward>)\n",
      "tensor([[16.4810]], grad_fn=<MmBackward>)\n",
      "tensor([[0.9441]], grad_fn=<MmBackward>)\n",
      "tensor([[0.1209]], grad_fn=<MmBackward>)\n",
      "tensor([[2.3244]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.6377]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0843]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.2511]], grad_fn=<MmBackward>)\n",
      "tensor([[-7.5081]], grad_fn=<MmBackward>)\n",
      "tensor([[0.7227]], grad_fn=<MmBackward>)\n",
      "tensor([[0.4750]], grad_fn=<MmBackward>)\n",
      "tensor([[-9.2035]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2947]], grad_fn=<MmBackward>)\n",
      "tensor([[0.9632]], grad_fn=<MmBackward>)\n",
      "tensor([[15.1767]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.8751]], grad_fn=<MmBackward>)\n",
      "tensor([[12.8131]], grad_fn=<MmBackward>)\n",
      "tensor([[0.1090]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0330]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.6486]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.4710]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.0686]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.9474]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.3521]], grad_fn=<MmBackward>)\n",
      "tensor([[6.2648]], grad_fn=<MmBackward>)\n",
      "tensor([[31.3352]], grad_fn=<MmBackward>)\n",
      "tensor([[0.1152]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.7057]], grad_fn=<MmBackward>)\n",
      "tensor([[13.1415]], grad_fn=<MmBackward>)\n",
      "tensor([[4.4140]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.7207]], grad_fn=<MmBackward>)\n",
      "tensor([[7.3208]], grad_fn=<MmBackward>)\n",
      "tensor([[0.4136]], grad_fn=<MmBackward>)\n",
      "tensor([[16.4764]], grad_fn=<MmBackward>)\n",
      "tensor([[3.9216]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.3756]], grad_fn=<MmBackward>)\n",
      "tensor([[10.8560]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.1996]], grad_fn=<MmBackward>)\n",
      "tensor([[4.7595]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1896]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.1870]], grad_fn=<MmBackward>)\n",
      "tensor([[0.7943]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.1521]], grad_fn=<MmBackward>)\n",
      "tensor([[4.0913]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6369]], grad_fn=<MmBackward>)\n",
      "tensor([[4.8560]], grad_fn=<MmBackward>)\n",
      "tensor([[1.7759]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0464]], grad_fn=<MmBackward>)\n",
      "tensor([[1.4673]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.5646]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.3695]], grad_fn=<MmBackward>)\n",
      "tensor([[29.2662]], grad_fn=<MmBackward>)\n",
      "tensor([[-20.6506]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.7309]], grad_fn=<MmBackward>)\n",
      "tensor([[2.0117]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0371]], grad_fn=<MmBackward>)\n",
      "tensor([[-19.4049]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.6551]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.2381]], grad_fn=<MmBackward>)\n",
      "tensor([[1.5762]], grad_fn=<MmBackward>)\n",
      "tensor([[10.7029]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3251]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.8140]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.2307]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.7307]], grad_fn=<MmBackward>)\n",
      "tensor([[12.3490]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.8151]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.2564]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.3819]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.1620]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.1404]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.6591]], grad_fn=<MmBackward>)\n",
      "tensor([[0.9386]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.3720]], grad_fn=<MmBackward>)\n",
      "tensor([[-10.0695]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.7485]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.8564]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2319]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.0917]], grad_fn=<MmBackward>)\n",
      "tensor([[2.0169]], grad_fn=<MmBackward>)\n",
      "tensor([[-7.5694]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.3975]], grad_fn=<MmBackward>)\n",
      "tensor([[3.9312]], grad_fn=<MmBackward>)\n",
      "tensor([[5.3478]], grad_fn=<MmBackward>)\n",
      "tensor([[2.6513]], grad_fn=<MmBackward>)\n",
      "tensor([[2.6951]], grad_fn=<MmBackward>)\n",
      "tensor([[-21.1422]], grad_fn=<MmBackward>)\n",
      "tensor([[2.6908]], grad_fn=<MmBackward>)\n",
      "tensor([[9.5891]], grad_fn=<MmBackward>)\n",
      "tensor([[3.0177]], grad_fn=<MmBackward>)\n",
      "tensor([[0.6302]], grad_fn=<MmBackward>)\n",
      "tensor([[8.3307]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.6707]], grad_fn=<MmBackward>)\n",
      "tensor([[1.9902]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3501]], grad_fn=<MmBackward>)\n",
      "tensor([[22.2586]], grad_fn=<MmBackward>)\n",
      "tensor([[-9.8066]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.6645]], grad_fn=<MmBackward>)\n",
      "tensor([[7.4083]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.7814]], grad_fn=<MmBackward>)\n",
      "tensor([[1.9111]], grad_fn=<MmBackward>)\n",
      "tensor([[4.1207]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0302]], grad_fn=<MmBackward>)\n",
      "tensor([[4.6711]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.7698]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.4189]], grad_fn=<MmBackward>)\n",
      "tensor([[4.3983]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.2228]], grad_fn=<MmBackward>)\n",
      "tensor([[5.9756]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.7743]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0487]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0592]], grad_fn=<MmBackward>)\n",
      "tensor([[2.4340]], grad_fn=<MmBackward>)\n",
      "tensor([[4.2643]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.4711]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.7905]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.2225]], grad_fn=<MmBackward>)\n",
      "tensor([[11.9943]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.4051]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1208]], grad_fn=<MmBackward>)\n",
      "tensor([[11.0667]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.5571]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.2946]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.2695]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.0730]], grad_fn=<MmBackward>)\n",
      "tensor([[1.8451]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.0526]], grad_fn=<MmBackward>)\n",
      "tensor([[-13.4670]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0943]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.1316]], grad_fn=<MmBackward>)\n",
      "tensor([[3.4934]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.8063]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.5537]], grad_fn=<MmBackward>)\n",
      "tensor([[2.7491]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.2932]], grad_fn=<MmBackward>)\n",
      "tensor([[2.4842]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.4821]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0416]], grad_fn=<MmBackward>)\n",
      "tensor([[-15.8795]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0539]], grad_fn=<MmBackward>)\n",
      "tensor([[5.3391]], grad_fn=<MmBackward>)\n",
      "tensor([[-7.5141]], grad_fn=<MmBackward>)\n",
      "tensor([[-10.9119]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.6429]], grad_fn=<MmBackward>)\n",
      "tensor([[2.9502]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.3254]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.5370]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.6448]], grad_fn=<MmBackward>)\n",
      "tensor([[-9.4041]], grad_fn=<MmBackward>)\n",
      "tensor([[7.2834]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.9641]], grad_fn=<MmBackward>)\n",
      "tensor([[13.7409]], grad_fn=<MmBackward>)\n",
      "tensor([[7.3870]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.1573]], grad_fn=<MmBackward>)\n",
      "tensor([[1.5523]], grad_fn=<MmBackward>)\n",
      "tensor([[0.2683]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.6050]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.2113]], grad_fn=<MmBackward>)\n",
      "tensor([[-8.8550]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.2040]], grad_fn=<MmBackward>)\n",
      "tensor([[7.2306]], grad_fn=<MmBackward>)\n",
      "tensor([[4.2574]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0974]], grad_fn=<MmBackward>)\n",
      "tensor([[17.0096]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.0592]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.1290]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.6299]], grad_fn=<MmBackward>)\n",
      "tensor([[-11.9310]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.4471]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.1398]], grad_fn=<MmBackward>)\n",
      "tensor([[0.7948]], grad_fn=<MmBackward>)\n",
      "tensor([[0.4132]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.5160]], grad_fn=<MmBackward>)\n",
      "tensor([[0.6022]], grad_fn=<MmBackward>)\n",
      "tensor([[2.6061]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.1168]], grad_fn=<MmBackward>)\n",
      "tensor([[8.2540]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.1059]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.7704]], grad_fn=<MmBackward>)\n",
      "tensor([[3.3022]], grad_fn=<MmBackward>)\n",
      "tensor([[0.2819]], grad_fn=<MmBackward>)\n",
      "tensor([[8.0104]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0068]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.1468]], grad_fn=<MmBackward>)\n",
      "tensor([[0.2914]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2000]], grad_fn=<MmBackward>)\n",
      "tensor([[-7.3719]], grad_fn=<MmBackward>)\n",
      "tensor([[3.7766]], grad_fn=<MmBackward>)\n",
      "tensor([[9.0091]], grad_fn=<MmBackward>)\n",
      "tensor([[18.2859]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.2872]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.4915]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.7445]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0669]], grad_fn=<MmBackward>)\n",
      "tensor([[2.6906]], grad_fn=<MmBackward>)\n",
      "tensor([[5.0859]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.2787]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.7372]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0748]], grad_fn=<MmBackward>)\n",
      "tensor([[1.7434]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.6074]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.3632]], grad_fn=<MmBackward>)\n",
      "tensor([[14.5980]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.1315]], grad_fn=<MmBackward>)\n",
      "tensor([[26.1500]], grad_fn=<MmBackward>)\n",
      "tensor([[-19.9249]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.6943]], grad_fn=<MmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1682]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.8289]], grad_fn=<MmBackward>)\n",
      "tensor([[14.2039]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.4843]], grad_fn=<MmBackward>)\n",
      "tensor([[6.9760]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0560]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.6640]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.9969]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.3984]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.9710]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0869]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.2777]], grad_fn=<MmBackward>)\n",
      "tensor([[7.7262]], grad_fn=<MmBackward>)\n",
      "tensor([[7.7461]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0556]], grad_fn=<MmBackward>)\n",
      "tensor([[0.1763]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.2189]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8369]], grad_fn=<MmBackward>)\n",
      "tensor([[4.9628]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.2168]], grad_fn=<MmBackward>)\n",
      "tensor([[8.5615]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0723]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.2352]], grad_fn=<MmBackward>)\n",
      "tensor([[5.3622]], grad_fn=<MmBackward>)\n",
      "tensor([[13.5210]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.7757]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.0812]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0500]], grad_fn=<MmBackward>)\n",
      "tensor([[11.1449]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0345]], grad_fn=<MmBackward>)\n",
      "tensor([[4.3352]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.8539]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.2825]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.5219]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.7870]], grad_fn=<MmBackward>)\n",
      "tensor([[0.1040]], grad_fn=<MmBackward>)\n",
      "tensor([[1.6389]], grad_fn=<MmBackward>)\n",
      "tensor([[3.9090]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8169]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0817]], grad_fn=<MmBackward>)\n",
      "tensor([[3.0404]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.6886]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.2396]], grad_fn=<MmBackward>)\n",
      "tensor([[0.1672]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.9557]], grad_fn=<MmBackward>)\n",
      "tensor([[-14.1095]], grad_fn=<MmBackward>)\n",
      "tensor([[1.3094]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0851]], grad_fn=<MmBackward>)\n",
      "tensor([[8.3249]], grad_fn=<MmBackward>)\n",
      "tensor([[0.1986]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.8453]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3997]], grad_fn=<MmBackward>)\n",
      "tensor([[3.3482]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.7423]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.3700]], grad_fn=<MmBackward>)\n",
      "tensor([[3.7331]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.0080]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.5662]], grad_fn=<MmBackward>)\n",
      "tensor([[2.2445]], grad_fn=<MmBackward>)\n",
      "tensor([[-23.9823]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.5998]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.5168]], grad_fn=<MmBackward>)\n",
      "tensor([[2.5076]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.3587]], grad_fn=<MmBackward>)\n",
      "tensor([[17.0167]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2943]], grad_fn=<MmBackward>)\n",
      "tensor([[5.2557]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.8821]], grad_fn=<MmBackward>)\n",
      "tensor([[0.7771]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0038]], grad_fn=<MmBackward>)\n",
      "tensor([[12.5914]], grad_fn=<MmBackward>)\n",
      "tensor([[3.5134]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.4691]], grad_fn=<MmBackward>)\n",
      "tensor([[10.7345]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0674]], grad_fn=<MmBackward>)\n",
      "tensor([[15.2349]], grad_fn=<MmBackward>)\n",
      "tensor([[8.7968]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.7657]], grad_fn=<MmBackward>)\n",
      "tensor([[2.2650]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2435]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0883]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.5277]], grad_fn=<MmBackward>)\n",
      "tensor([[8.6640]], grad_fn=<MmBackward>)\n",
      "tensor([[1.2924]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3820]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.3443]], grad_fn=<MmBackward>)\n",
      "tensor([[6.2796]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0930]], grad_fn=<MmBackward>)\n",
      "tensor([[9.6439]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.2088]], grad_fn=<MmBackward>)\n",
      "tensor([[2.7684]], grad_fn=<MmBackward>)\n",
      "tensor([[2.2432]], grad_fn=<MmBackward>)\n",
      "tensor([[6.0691]], grad_fn=<MmBackward>)\n",
      "tensor([[17.3548]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.9788]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.8252]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.3783]], grad_fn=<MmBackward>)\n",
      "tensor([[2.6680]], grad_fn=<MmBackward>)\n",
      "tensor([[4.2026]], grad_fn=<MmBackward>)\n",
      "tensor([[7.0099]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.3899]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3194]], grad_fn=<MmBackward>)\n",
      "tensor([[2.3250]], grad_fn=<MmBackward>)\n",
      "tensor([[9.7513]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.0534]], grad_fn=<MmBackward>)\n",
      "tensor([[0.2353]], grad_fn=<MmBackward>)\n",
      "tensor([[3.5712]], grad_fn=<MmBackward>)\n",
      "tensor([[-7.4286]], grad_fn=<MmBackward>)\n",
      "tensor([[-17.8705]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3708]], grad_fn=<MmBackward>)\n",
      "tensor([[4.1766]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.6751]], grad_fn=<MmBackward>)\n",
      "tensor([[9.8862]], grad_fn=<MmBackward>)\n",
      "tensor([[0.7013]], grad_fn=<MmBackward>)\n",
      "tensor([[11.4841]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1069]], grad_fn=<MmBackward>)\n",
      "tensor([[4.0828]], grad_fn=<MmBackward>)\n",
      "tensor([[0.1020]], grad_fn=<MmBackward>)\n",
      "tensor([[-10.5141]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.0860]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.4873]], grad_fn=<MmBackward>)\n",
      "tensor([[3.0433]], grad_fn=<MmBackward>)\n",
      "tensor([[5.1294]], grad_fn=<MmBackward>)\n",
      "tensor([[0.2763]], grad_fn=<MmBackward>)\n",
      "tensor([[-9.0268]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.5508]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.7068]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.0131]], grad_fn=<MmBackward>)\n",
      "tensor([[5.6078]], grad_fn=<MmBackward>)\n",
      "tensor([[7.2241]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.7695]], grad_fn=<MmBackward>)\n",
      "tensor([[1.7744]], grad_fn=<MmBackward>)\n",
      "tensor([[-9.1286]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.8097]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.5552]], grad_fn=<MmBackward>)\n",
      "tensor([[19.2572]], grad_fn=<MmBackward>)\n",
      "tensor([[10.0116]], grad_fn=<MmBackward>)\n",
      "tensor([[6.7825]], grad_fn=<MmBackward>)\n",
      "tensor([[9.0818]], grad_fn=<MmBackward>)\n",
      "tensor([[2.7776]], grad_fn=<MmBackward>)\n",
      "tensor([[3.7958]], grad_fn=<MmBackward>)\n",
      "tensor([[-9.2897]], grad_fn=<MmBackward>)\n",
      "tensor([[0.9734]], grad_fn=<MmBackward>)\n",
      "tensor([[0.1569]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.4068]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.0754]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.3849]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.7748]], grad_fn=<MmBackward>)\n",
      "tensor([[3.0226]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.5879]], grad_fn=<MmBackward>)\n",
      "tensor([[4.5530]], grad_fn=<MmBackward>)\n",
      "tensor([[1.9519]], grad_fn=<MmBackward>)\n",
      "tensor([[-10.0272]], grad_fn=<MmBackward>)\n",
      "tensor([[7.0624]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.0224]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.5290]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.3105]], grad_fn=<MmBackward>)\n",
      "tensor([[-11.1908]], grad_fn=<MmBackward>)\n",
      "tensor([[0.6009]], grad_fn=<MmBackward>)\n",
      "tensor([[0.6381]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.3055]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.7595]], grad_fn=<MmBackward>)\n",
      "tensor([[6.9762]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0060]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.4923]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.0083]], grad_fn=<MmBackward>)\n",
      "tensor([[2.0356]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.0484]], grad_fn=<MmBackward>)\n",
      "tensor([[-9.0812]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.5653]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.3965]], grad_fn=<MmBackward>)\n",
      "tensor([[4.5286]], grad_fn=<MmBackward>)\n",
      "tensor([[-28.7486]], grad_fn=<MmBackward>)\n",
      "tensor([[1.4131]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.1182]], grad_fn=<MmBackward>)\n",
      "tensor([[2.8993]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.4665]], grad_fn=<MmBackward>)\n",
      "tensor([[4.6903]], grad_fn=<MmBackward>)\n",
      "tensor([[1.2948]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.9302]], grad_fn=<MmBackward>)\n",
      "tensor([[-9.8376]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.6785]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.5829]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.8602]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.1839]], grad_fn=<MmBackward>)\n",
      "tensor([[2.9627]], grad_fn=<MmBackward>)\n",
      "tensor([[-17.3313]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.1261]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.6375]], grad_fn=<MmBackward>)\n",
      "tensor([[-7.1509]], grad_fn=<MmBackward>)\n",
      "tensor([[-16.7576]], grad_fn=<MmBackward>)\n",
      "tensor([[1.9848]], grad_fn=<MmBackward>)\n",
      "tensor([[5.3109]], grad_fn=<MmBackward>)\n",
      "tensor([[5.8115]], grad_fn=<MmBackward>)\n",
      "tensor([[9.1461]], grad_fn=<MmBackward>)\n",
      "tensor([[-8.7148]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0174]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.9308]], grad_fn=<MmBackward>)\n",
      "tensor([[2.0057]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.3201]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.2643]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0733]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.1265]], grad_fn=<MmBackward>)\n",
      "tensor([[13.0435]], grad_fn=<MmBackward>)\n",
      "tensor([[2.9622]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.9201]], grad_fn=<MmBackward>)\n",
      "tensor([[6.0987]], grad_fn=<MmBackward>)\n",
      "tensor([[4.2429]], grad_fn=<MmBackward>)\n",
      "tensor([[1.3996]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.9059]], grad_fn=<MmBackward>)\n",
      "tensor([[0.2704]], grad_fn=<MmBackward>)\n",
      "tensor([[-6.4160]], grad_fn=<MmBackward>)\n",
      "tensor([[3.2445]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.6612]], grad_fn=<MmBackward>)\n",
      "tensor([[0.3005]], grad_fn=<MmBackward>)\n",
      "tensor([[1.3514]], grad_fn=<MmBackward>)\n",
      "tensor([[12.5595]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.9778]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.0313]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.8610]], grad_fn=<MmBackward>)\n",
      "tensor([[0.5050]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.1798]], grad_fn=<MmBackward>)\n",
      "tensor([[4.1802]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.5264]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.0772]], grad_fn=<MmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3964]], grad_fn=<MmBackward>)\n",
      "tensor([[0.2247]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0138]], grad_fn=<MmBackward>)\n",
      "tensor([[5.0344]], grad_fn=<MmBackward>)\n",
      "tensor([[8.4647]], grad_fn=<MmBackward>)\n",
      "tensor([[0.0575]], grad_fn=<MmBackward>)\n",
      "tensor([[0.5135]], grad_fn=<MmBackward>)\n",
      "tensor([[13.2787]], grad_fn=<MmBackward>)\n",
      "tensor([[7.9870]], grad_fn=<MmBackward>)\n",
      "tensor([[27.3812]], grad_fn=<MmBackward>)\n",
      "tensor([[7.3710]], grad_fn=<MmBackward>)\n",
      "tensor([[12.1896]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.4429]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.0411]], grad_fn=<MmBackward>)\n",
      "tensor([[2.6782]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.3610]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.6694]], grad_fn=<MmBackward>)\n",
      "tensor([[3.5372]], grad_fn=<MmBackward>)\n",
      "tensor([[1.4067]], grad_fn=<MmBackward>)\n",
      "tensor([[-5.9603]], grad_fn=<MmBackward>)\n",
      "tensor([[-9.1578]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.1885]], grad_fn=<MmBackward>)\n",
      "tensor([[2.5209]], grad_fn=<MmBackward>)\n",
      "tensor([[16.0492]], grad_fn=<MmBackward>)\n",
      "tensor([[11.2260]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.8701]], grad_fn=<MmBackward>)\n",
      "tensor([[-7.1694]], grad_fn=<MmBackward>)\n",
      "tensor([[5.5341]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.0907]], grad_fn=<MmBackward>)\n",
      "tensor([[6.1680]], grad_fn=<MmBackward>)\n",
      "tensor([[19.4694]], grad_fn=<MmBackward>)\n",
      "tensor([[-3.5575]], grad_fn=<MmBackward>)\n",
      "tensor([[2.1934]], grad_fn=<MmBackward>)\n",
      "tensor([[-7.2625]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.5264]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1109]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.8972]], grad_fn=<MmBackward>)\n",
      "tensor([[6.6834]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.8584]], grad_fn=<MmBackward>)\n",
      "tensor([[1.1417]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.7184]], grad_fn=<MmBackward>)\n",
      "tensor([[-8.8431]], grad_fn=<MmBackward>)\n",
      "tensor([[-4.6561]], grad_fn=<MmBackward>)\n",
      "tensor([[-15.2372]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.4053]], grad_fn=<MmBackward>)\n",
      "tensor([[15.7605]], grad_fn=<MmBackward>)\n",
      "tensor([[13.2828]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.9642]], grad_fn=<MmBackward>)\n",
      "tensor([[1.0380]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.4390]], grad_fn=<MmBackward>)\n",
      "tensor([[12.4864]], grad_fn=<MmBackward>)\n",
      "tensor([[0.5610]], grad_fn=<MmBackward>)\n",
      "tensor([[4.5228]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.1956]], grad_fn=<MmBackward>)\n",
      "tensor([[12.0505]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(500):\n",
    "    x = torch.randn(100)\n",
    "    K = kernel(x, x)\n",
    "    x2 = torch.randn(100)\n",
    "    print(x2[None, :] @ K.evaluate() @ x2[:, None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ecbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
