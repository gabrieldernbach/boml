{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23458cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load, split, ScaleAbsOne\n",
    "import torch\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0bf022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.43it/s]\n"
     ]
    }
   ],
   "source": [
    "df = load()\n",
    "train, dev, test = split(df, \"new_dose-response_matrices\", inner_fold=1, outer_fold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92e7798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = np.array(train.pop(\"PercentageGrowth\"))\n",
    "dev_target = np.array(dev.pop(\"PercentageGrowth\"))\n",
    "test_target = np.array(test.pop(\"PercentageGrowth\"))\n",
    "scaler = ScaleAbsOne()\n",
    "train = scaler.fit_transform(train.values)\n",
    "dev = scaler.transform(dev.values)\n",
    "test = scaler.transform(test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05364785",
   "metadata": {},
   "source": [
    "# multi linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d12821",
   "metadata": {},
   "source": [
    "$$\n",
    "k_\\gamma(x,y) = \\prod_k^K \\frac{\\gamma^2 + x_k y_k}{\\gamma^2 + 1}\n",
    "$$\n",
    "alternatively use the logarithmized space\n",
    "$$\n",
    "k_\\gamma(x, y) = \\sum_k^K \\log\\left(\\frac{\\gamma^2 + x_k y_k}{\\gamma^2 + 1}\\right)\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9b745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLinearKernel:\n",
    "    def __init__(self, scale: Union[float, np.array]):\n",
    "        self.scale = scale\n",
    "        \n",
    "    def __call__(self, x1, x2):\n",
    "        prod = np.einsum(\"nd, md -> nmd\", x1, x2)\n",
    "        frac = (self.scale**2 + prod) / (1 + self.scale**2)\n",
    "        return frac.prod(axis=-1)\n",
    "\n",
    "# class LogMultiLinearKernel:\n",
    "#     def __init__(self, scale: int):\n",
    "#         self.scale = scale  # make vector later\n",
    "        \n",
    "#     def __call__(self, x1, x2):\n",
    "#         prod = np.einsum(\"nd, md -> nmd\", x1, x2)\n",
    "#         frac = (self.scale**2 + prod) / (1 + self.scale**2)\n",
    "#         return np.log(frac).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08900d5a",
   "metadata": {},
   "source": [
    "# Nystroem approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e61281",
   "metadata": {},
   "source": [
    "credit: https://stats.stackexchange.com/questions/261149/nystroem-method-for-kernel-approximation \n",
    "\n",
    "Assume $K \\in R^{n\\times n}$ has rank $m << n$ and let $K_{11}$ be of shape $m\\times m$\n",
    "\\begin{align}\n",
    "K = \\begin{bmatrix}\n",
    "K_{11} & K_{21}^T\\\\\n",
    "K_{21} & K_{22}\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Assume the eigen decomposition\n",
    "\\begin{align}\n",
    "K &= U \\Lambda U^T \\\\ \n",
    "&= \\begin{bmatrix} U_1 \\\\ U_2 \\end{bmatrix} \\Lambda\\begin{bmatrix} U_1 \\\\ U_2 \\end{bmatrix}^T \\\\\n",
    "&= \\begin{bmatrix} U_1 \\Lambda U_1^T & U_1 \\Lambda U_2^T \\\\\n",
    "U_2 \\Lambda U_1^T & U_2 \\Lambda U_2^T\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "As m << n it is easy to compute $K_{11} = U_1 \\Lambda U_1^T$.\n",
    "\n",
    "Which also allows us to solve for $U_2 = K_{21} U_1 \\Lambda^{-1}$.\n",
    "\n",
    "And substitute into \n",
    "\\begin{align}\n",
    "K_{22} &= U_2 \\Lambda U_2^T \\\\\n",
    "&= (K_{21} U_1 \\Lambda^{-1}) \\Lambda (K_{21} U_1 \\Lambda^{-1})^T \\\\\n",
    "&= K_{21} U_1 \\Lambda^{-1} U_1^T K_{21}^T \\\\\n",
    "&= K_{21} K_{11}^{-1} K_{21}^T \\\\\n",
    "&= \\left(K_{21} K_{11}^{-\\frac{1}{2}}\\right) \\left(K_{21} K_{11}^{-\\frac{1}{2}}\\right)^T\n",
    "\\end{align}\n",
    "\n",
    "Which implies the following explicit feature map\n",
    "\\begin{align}\n",
    "\\Phi = \\begin{bmatrix}\n",
    "K_{11}^{\\frac{1}{2}} \\\\ K_{21}K_{11}^{-\\frac{1}{2}}\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "For which we can show that \n",
    "\\begin{align}\n",
    "\\Phi \\Phi^T = \n",
    "\\begin{bmatrix}\n",
    "K_{11} & K_{21}^T \\\\\n",
    "K_{21} & K_{21} K_{11}^{-1} K_{21}^T\n",
    "\\end{bmatrix} = K\n",
    "\\end{align}\n",
    "\n",
    "We sample $m$ datapoints and compute $K_{11}^{-\\frac{1}{2}}$ and arrive at the final result\n",
    "$$\\phi(X_\\star) = K_{\\star 1} K_{11}^{-\\frac{1}{2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9abce2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(method):\n",
    "    def wrapped(self, x):\n",
    "        bs = self.batch_size\n",
    "        out = [method(self, x[b:b+bs]) for b in tqdm(range(0, len(x), bs))]\n",
    "        return np.concatenate(out, axis=0)\n",
    "    return wrapped\n",
    "\n",
    "class Nystroem:\n",
    "    def __init__(self, kernel: callable, n_components: int, batch_size=512):\n",
    "        self.n_components = n_components\n",
    "        self.kernel = kernel\n",
    "        self.batch_size= batch_size\n",
    "        \n",
    "    def fit(self, x):\n",
    "        n, d = x.shape\n",
    "        idx = np.random.permutation(n)[:self.n_components]\n",
    "        basis = x[idx]\n",
    "        \n",
    "        k = self.kernel(basis, basis)\n",
    "        u, s, v = np.linalg.svd(k)\n",
    "        # for stability, credit sklearn\n",
    "        s = np.maximum(s, 1e-12)\n",
    "        \n",
    "        self.normalization_ = (u / np.sqrt(s)) @ v\n",
    "        self.components_ = basis\n",
    "        self.component_indices_ = idx\n",
    "        return self\n",
    "    \n",
    "    @batched\n",
    "    def transform(self, x):\n",
    "        embedded = self.kernel(x, self.components_)\n",
    "        features = embedded @ self.normalization_.T\n",
    "        return features\n",
    "    \n",
    "    def fit_transform(self, x):\n",
    "        self.fit(x)\n",
    "        return self.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c205aed",
   "metadata": {},
   "source": [
    "# bayesian linear regressionm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41513115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLinearRegression:\n",
    "    # see Bishop - Pattern Recognition And Machine Learning\n",
    "    # page 31. equations (1.70 - 1.72)\n",
    "    def __init__(self, alpha=1e-13, beta=1):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        n, d = x.shape\n",
    "        S_inv = self.alpha * np.eye(d) + self.beta * x.T @ x\n",
    "        self.S = np.linalg.pinv(S_inv)\n",
    "        self.m = self.S @ x.T @ y\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y = self.beta * x @ self.m\n",
    "        y_var = 1 / self.beta + np.einsum(\"ij, jk, ki -> i\", x, self.S, x.T, optimize=True)\n",
    "        return y, np.sqrt(y_var)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        self.fit(x, y)\n",
    "        diff = y - self.predict(x)[0]\n",
    "        mse = (diff**2).mean()\n",
    "        explained_variance = 1 - (diff.var() / y.var())\n",
    "        return mse, explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de07cf",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "777f5756",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(len(train))[:1024]\n",
    "train_sub = train[idx]\n",
    "train_target_sub = train_target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c56b58a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785.4425561869423, 0.5376965167286726)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plain linear regression\n",
    "BayesianLinearRegression().score(train_sub, train_target_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ade9607e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.3580375890981282e-23, 1.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# polynomial kernel regression\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch\n",
    "Xp = PolynomialCountSketch(gamma=1.0, degree=2, n_components=2048).fit_transform(train_sub)\n",
    "BayesianLinearRegression().score(Xp, train_target_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "daa6f9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7414046778352082e-08, 0.9999999999898144)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mlk-kernel regression\n",
    "phi = MultiLinearKernel(scale=10)(train_sub, train_sub)\n",
    "BayesianLinearRegression().score(phi, train_target_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecc7bc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.1395851309376377e-16, 1.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mlk-nystroem regression, full\n",
    "mlk = MultiLinearKernel(scale=10)\n",
    "phi = Nystroem(kernel=mlk, n_components=1024).fit_transform(train_sub)\n",
    "BayesianLinearRegression().score(phi, train_target_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62772c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(434.837760761155, 0.7440589259284915)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mlk-nystroem regression half\n",
    "mlk = MultiLinearKernel(scale=10)\n",
    "phi = Nystroem(kernel=mlk, n_components=512).fit_transform(train_sub)\n",
    "BayesianLinearRegression().score(phi, train_target_sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
