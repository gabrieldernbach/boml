{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e6a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "from sys import argv\n",
    "from comboFM_core_data.utils import concatenate_features, standardize\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470e4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123 # Random seed\n",
    "data_dir = \"comboFM_core_data/data/data/\"\n",
    "\n",
    "nfolds_outer = 10 # Number of folds in the outer loop\n",
    "nfolds_inner = 5 # Number of folds in the inner loop\n",
    "\n",
    "# Experiment: 1) new_dose-response_matrix_entries, 2) new_dose-response_matrices, 3) new_drug_combinations\"\"\"\n",
    "experiment = \"new_drug_combinations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b8195e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 2\n",
      "Reading file: drug1_concentration__one-hot_encoding.csv\n",
      "Reading file: drug2_concentration__one-hot_encoding.csv\n",
      "Reading file: drug1__one-hot_encoding.csv\n",
      "Reading file: drug2__one-hot_encoding.csv\n",
      "Reading file: cell_lines__one-hot_encoding.csv\n",
      "... done!\n",
      "Reading file: drug1_drug2_concentration__values.csv\n",
      "Reading file: drug1__estate_fingerprints.csv\n",
      "Reading file: drug2__estate_fingerprints.csv\n",
      "Reading file: cell_lines__gene_expression.csv\n",
      "... done!\n",
      "Reading file: drug2_concentration__one-hot_encoding.csv\n",
      "Reading file: drug1_concentration__one-hot_encoding.csv\n",
      "Reading file: drug2__one-hot_encoding.csv\n",
      "Reading file: drug1__one-hot_encoding.csv\n",
      "Reading file: cell_lines__one-hot_encoding.csv\n",
      "... done!\n",
      "Reading file: drug2_drug1_concentration__values.csv\n",
      "Reading file: drug2__estate_fingerprints.csv\n",
      "Reading file: drug1__estate_fingerprints.csv\n",
      "Reading file: cell_lines__gene_expression.csv\n",
      "... done!\n",
      "Dataset shape: (1110600, 400)\n",
      "Non-zeros rate: 0.25707\n",
      "Number of one-hot encoding features: 252\n",
      "Number of auxiliary features: 148\n"
     ]
    }
   ],
   "source": [
    "id_in = 2\n",
    "print(\"\\nJob ID: %d\" %id_in)\n",
    "\n",
    " # Features in position 1: Drug A - Drug B\n",
    "features_tensor_1 = (\n",
    "    \"drug1_concentration__one-hot_encoding.csv\", \n",
    "    \"drug2_concentration__one-hot_encoding.csv\", \n",
    "    \"drug1__one-hot_encoding.csv\", \n",
    "    \"drug2__one-hot_encoding.csv\", \n",
    "    \"cell_lines__one-hot_encoding.csv\"\n",
    ")\n",
    "features_auxiliary_1 = (\n",
    "    \"drug1_drug2_concentration__values.csv\", \n",
    "    \"drug1__estate_fingerprints.csv\", \n",
    "    \"drug2__estate_fingerprints.csv\", \n",
    "    \"cell_lines__gene_expression.csv\"\n",
    ")\n",
    "X_tensor_1 = concatenate_features(data_dir, features_tensor_1)\n",
    "X_auxiliary_1 = concatenate_features(data_dir, features_auxiliary_1)\n",
    "X_1 = np.concatenate((X_tensor_1, X_auxiliary_1), axis = 1)\n",
    "\n",
    "# Features in position 2: Drug B - Drug A\n",
    "features_tensor_2 = (\n",
    "    \"drug2_concentration__one-hot_encoding.csv\", \n",
    "    \"drug1_concentration__one-hot_encoding.csv\", \n",
    "    \"drug2__one-hot_encoding.csv\", \n",
    "    \"drug1__one-hot_encoding.csv\", \n",
    "    \"cell_lines__one-hot_encoding.csv\"\n",
    ")\n",
    "features_auxiliary_2 =(\n",
    "    \"drug2_drug1_concentration__values.csv\", \n",
    "    \"drug2__estate_fingerprints.csv\", \n",
    "    \"drug1__estate_fingerprints.csv\", \n",
    "    \"cell_lines__gene_expression.csv\"\n",
    ")\n",
    "X_tensor_2 = concatenate_features(data_dir, features_tensor_2)\n",
    "X_auxiliary_2 = concatenate_features(data_dir, features_auxiliary_2)\n",
    "X_2 = np.concatenate((X_tensor_2, X_auxiliary_2), axis = 1)\n",
    "\n",
    "# Concatenate the features from both positions vertically\n",
    "X = np.concatenate((X_1, X_2), axis=0)\n",
    "print('Dataset shape: {}'.format(X.shape))\n",
    "print('Non-zeros rate: {:.05f}'.format(np.mean(X != 0)))\n",
    "print('Number of one-hot encoding features: {}'.format(X_tensor_1.shape[1]))\n",
    "print('Number of auxiliary features: {}'.format(X_auxiliary_1.shape[1]))\n",
    "i_aux = X_tensor_1.shape[1]\n",
    "del X_tensor_1, X_auxiliary_1, X_tensor_2, X_auxiliary_2, X_1, X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e221dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1043640, 400)\n",
      "Test set shape: (66960, 400)\n"
     ]
    }
   ],
   "source": [
    "# Read responses\n",
    "y  = np.loadtxt(\"comboFM_core_data/data/data/responses.csv\", delimiter = \",\", skiprows = 1)\n",
    "y = np.concatenate((y, y), axis=0)\n",
    "\n",
    "inner_folds = list(range(1, nfolds_inner+1))\n",
    "outer_folds = list(range(1, nfolds_outer+1))\n",
    "\n",
    "outer_fold = outer_folds[id_in]\n",
    "te_idx = np.loadtxt('comboFM_core_data/cross-validation_folds/%s/test_idx_outer_fold-%d.txt'%(experiment, outer_fold)).astype(int)\n",
    "tr_idx = np.loadtxt('comboFM_core_data/cross-validation_folds/%s/train_idx_outer_fold-%d.txt'%(experiment, outer_fold)).astype(int)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = X[tr_idx,:], X[te_idx,:], y[tr_idx], y[te_idx]\n",
    "\n",
    "print('Training set shape: {}'.format(X_tr.shape))\n",
    "print('Test set shape: {}'.format(X_te.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b6339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"X_tr\": X_tr,\n",
    "    \"X_te\": X_te,\n",
    "    \"y_tr\": y_tr,\n",
    "    \"y_te\": y_te\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c90b41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106b18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data, open(\"split0.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa78774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
