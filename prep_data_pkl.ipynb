{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e6a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "from sys import argv\n",
    "from comboFM_core_data.utils import concatenate_features, standardize\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "470e4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123 # Random seed\n",
    "data_dir = \"comboFM_core_data/data/data/\"\n",
    "\n",
    "nfolds_outer = 10 # Number of folds in the outer loop\n",
    "nfolds_inner = 5 # Number of folds in the inner loop\n",
    "\n",
    "# Experiment: 1) new_dose-response_matrix_entries, 2) new_dose-response_matrices, 3) new_drug_combinations\"\"\"\n",
    "experiment = \"new_drug_combinations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b8195e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 2\n",
      "Reading file: drug1_concentration__one-hot_encoding.csv\n",
      "Reading file: drug2_concentration__one-hot_encoding.csv\n",
      "Reading file: drug1__one-hot_encoding.csv\n",
      "Reading file: drug2__one-hot_encoding.csv\n",
      "Reading file: cell_lines__one-hot_encoding.csv\n",
      "... done!\n",
      "Reading file: drug1_drug2_concentration__values.csv\n",
      "Reading file: drug1__estate_fingerprints.csv\n",
      "Reading file: drug2__estate_fingerprints.csv\n",
      "Reading file: cell_lines__gene_expression.csv\n",
      "... done!\n",
      "Reading file: drug2_concentration__one-hot_encoding.csv\n",
      "Reading file: drug1_concentration__one-hot_encoding.csv\n",
      "Reading file: drug2__one-hot_encoding.csv\n",
      "Reading file: drug1__one-hot_encoding.csv\n",
      "Reading file: cell_lines__one-hot_encoding.csv\n",
      "... done!\n",
      "Reading file: drug2_drug1_concentration__values.csv\n",
      "Reading file: drug2__estate_fingerprints.csv\n",
      "Reading file: drug1__estate_fingerprints.csv\n",
      "Reading file: cell_lines__gene_expression.csv\n",
      "... done!\n",
      "Dataset shape: (1110600, 400)\n",
      "Non-zeros rate: 0.25707\n",
      "Number of one-hot encoding features: 252\n",
      "Number of auxiliary features: 148\n"
     ]
    }
   ],
   "source": [
    "id_in = 2\n",
    "print(\"\\nJob ID: %d\" %id_in)\n",
    "\n",
    " # Features in position 1: Drug A - Drug B\n",
    "features_tensor_1 = (\n",
    "    \"drug1_concentration__one-hot_encoding.csv\", \n",
    "    \"drug2_concentration__one-hot_encoding.csv\", \n",
    "    \"drug1__one-hot_encoding.csv\", \n",
    "    \"drug2__one-hot_encoding.csv\", \n",
    "    \"cell_lines__one-hot_encoding.csv\"\n",
    ")\n",
    "features_auxiliary_1 = (\n",
    "    \"drug1_drug2_concentration__values.csv\", \n",
    "    \"drug1__estate_fingerprints.csv\", \n",
    "    \"drug2__estate_fingerprints.csv\", \n",
    "    \"cell_lines__gene_expression.csv\"\n",
    ")\n",
    "X_tensor_1 = concatenate_features(data_dir, features_tensor_1)\n",
    "X_auxiliary_1 = concatenate_features(data_dir, features_auxiliary_1)\n",
    "X_1 = np.concatenate((X_tensor_1, X_auxiliary_1), axis = 1)\n",
    "\n",
    "# Features in position 2: Drug B - Drug A\n",
    "features_tensor_2 = (\n",
    "    \"drug2_concentration__one-hot_encoding.csv\", \n",
    "    \"drug1_concentration__one-hot_encoding.csv\", \n",
    "    \"drug2__one-hot_encoding.csv\", \n",
    "    \"drug1__one-hot_encoding.csv\", \n",
    "    \"cell_lines__one-hot_encoding.csv\"\n",
    ")\n",
    "features_auxiliary_2 =(\n",
    "    \"drug2_drug1_concentration__values.csv\", \n",
    "    \"drug2__estate_fingerprints.csv\", \n",
    "    \"drug1__estate_fingerprints.csv\", \n",
    "    \"cell_lines__gene_expression.csv\"\n",
    ")\n",
    "X_tensor_2 = concatenate_features(data_dir, features_tensor_2)\n",
    "X_auxiliary_2 = concatenate_features(data_dir, features_auxiliary_2)\n",
    "X_2 = np.concatenate((X_tensor_2, X_auxiliary_2), axis = 1)\n",
    "\n",
    "# Concatenate the features from both positions vertically\n",
    "X = np.concatenate((X_1, X_2), axis=0)\n",
    "print('Dataset shape: {}'.format(X.shape))\n",
    "print('Non-zeros rate: {:.05f}'.format(np.mean(X != 0)))\n",
    "print('Number of one-hot encoding features: {}'.format(X_tensor_1.shape[1]))\n",
    "print('Number of auxiliary features: {}'.format(X_auxiliary_1.shape[1]))\n",
    "i_aux = X_tensor_1.shape[1]\n",
    "del X_tensor_1, X_auxiliary_1, X_tensor_2, X_auxiliary_2, X_1, X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e221dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../data/data/responses.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a484664446b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/data/responses.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minner_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfolds_inner\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/venv/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/venv/lib/python3.9/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/venv/lib/python3.9/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    533\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ../data/data/responses.csv not found."
     ]
    }
   ],
   "source": [
    "# Read responses\n",
    "y  = np.loadtxt(\"../data/data/responses.csv\", delimiter = \",\", skiprows = 1)\n",
    "y = np.concatenate((y, y), axis=0)\n",
    "\n",
    "inner_folds = list(range(1, nfolds_inner+1))\n",
    "outer_folds = list(range(1, nfolds_outer+1))\n",
    "\n",
    "outer_fold = outer_folds[id_in]\n",
    "te_idx = np.loadtxt('cross-validation_folds/%s/test_idx_outer_fold-%d.txt'%(experiment, outer_fold)).astype(int)\n",
    "tr_idx = np.loadtxt('cross-validation_folds/%s/train_idx_outer_fold-%d.txt'%(experiment, outer_fold)).astype(int)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = X[tr_idx,:], X[te_idx,:], y[tr_idx], y[te_idx]\n",
    "\n",
    "print('Training set shape: {}'.format(X_tr.shape))\n",
    "print('Test set shape: {}'.format(X_te.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"X_tr\": X_tr,\n",
    "    \"X_te\": X_te,\n",
    "    \"y_tr\": y_tr,\n",
    "    \"y_te\": y_te\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data, open(\"split0.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa78774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
